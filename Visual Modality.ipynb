{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the features and initialize the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Read feature names\n",
    "# ---------------------------------------\n",
    "\n",
    "f = open(\"openface_feature_names.json\", \"r\")\n",
    "all_features = json.load(f)\n",
    "f.close()\n",
    "\n",
    "#Regex to link feature names to what they represent\n",
    "feature_regex = {\n",
    "    \"action_units\": ['AU'],\n",
    "    \"gaze\": ['gaze'],\n",
    "    \"shape\": ['p_'],\n",
    "    \"landmarks_2d\": [' x_', ' y_'],\n",
    "    \"landmarks_3d\": [' X_', ' Y_', ' Z_'],\n",
    "    \"eye_lmk_2d\": [\"lmk_x\", \"lmk_y\"],\n",
    "    \"eye_lmk_3d\": [\"lmk_X\", \"lmk_Y\", \"lmk_Z\"],\n",
    "    \"output\": [\"rating\"]\n",
    "}\n",
    "features = defaultdict(list)\n",
    "for feature, regexes in feature_regex.items():\n",
    "    for col in all_features:\n",
    "        for regex in regexes:\n",
    "            if regex in col:\n",
    "                features[feature].append(col)\n",
    "\n",
    "#Features to use for training\n",
    "training_features = ['action_units', 'shape', 'landmarks_2d', 'eye_lmk_2d']\n",
    "training_features = [ftr_name for feature in training_features for ftr_name in features[feature]]\n",
    "\n",
    "feature_indices = sorted([all_features.index(feature) for feature in training_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used for training :  323\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "FEATURE_INDICES = feature_indices\n",
    "MAX_FRAMES_PER_VIDEO = 800 #Pad/Truncate data to maitain 800 frames\n",
    "FEATURE_COUNT = len(FEATURE_INDICES)\n",
    "print(\"Number of features used for training : \", FEATURE_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator to load data in batches to avoid memory overflow\n",
    "\n",
    "#Features and labels can be processed inside this generator\n",
    "def gen(ftr_files):\n",
    "    ftr_files = [file.decode() for file in ftr_files]\n",
    "    for i, file in enumerate(ftr_files):\n",
    "        #Ignore hidden files such as '.dstore'\n",
    "        if '.npy' not in file:\n",
    "            continue\n",
    "        try: #If any issues with reading the current file or missing label, ignore the video\n",
    "            ftrs = np.load(f'visual_features/{file}')\n",
    "            ftrs = ftrs[:, FEATURE_INDICES]\n",
    "            v_id = file.split('.')[0]\n",
    "            label = np.load(f'visual_labels/{file}')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        #Pad 0 valued frames(at the end) if frame count for the video lower than MAX_FRAMES_PER_VIDEO\n",
    "        #Delete frames(from the front) if frame count grater than MAX_FRAMES_PER_VIDEO\n",
    "        ftrs = tf.keras.preprocessing.sequence.pad_sequences([ftrs], maxlen=MAX_FRAMES_PER_VIDEO, \n",
    "                                                             dtype='float64', padding='post', \n",
    "                                                             truncating='pre', value=0.0)\n",
    "        yield ftrs[0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate an LSTM\n",
    "def generate_model(input_size, max_length):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = (input_size, max_length)))\n",
    "    \n",
    "    rnn_layer = tf.keras.layers.LSTM(units = 20, activation = 'sigmoid', dropout = 0, recurrent_dropout = 0, implementation = 1, return_sequences = False)\n",
    "    model.add(rnn_layer)\n",
    "    \n",
    "    dense_layer = tf.keras.layers.Dense(20)\n",
    "    model.add(dense_layer)\n",
    "    \n",
    "    dense_layer = tf.keras.layers.Dense(1)\n",
    "    model.add(dense_layer)\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-2))\n",
    "    model.build()\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the train and test datasets\n",
    "ftr_files = [file for file in os.listdir('visual_features/') if '.npy' in file]\n",
    "np.random.shuffle(ftr_files)\n",
    "\n",
    "#Keep x% of data as training\n",
    "file_count = len(ftr_files)\n",
    "train_size = 80 #In %age\n",
    "split_index = (file_count*80)//100\n",
    "\n",
    "train, test = ftr_files[:split_index], ftr_files[split_index:]\n",
    "\n",
    "#Training dataset\n",
    "dataset_train = tf.data.Dataset.from_generator(\n",
    "     gen, (tf.float64, tf.float64),\n",
    "     output_shapes=(tf.TensorShape((None, None)), tf.TensorShape(())), args=(train,))\n",
    "dataset_train_batched = dataset_train.batch(128, drop_remainder=True)\n",
    "dataset_train_batched_prefetched = dataset_train_batched.prefetch(1)\n",
    "\n",
    "#Test dataset\n",
    "dataset_test = tf.data.Dataset.from_generator(\n",
    "     gen, (tf.float64, tf.float64),\n",
    "     output_shapes=(tf.TensorShape((None, None)), tf.TensorShape(())), args=(test,))\n",
    "dataset_test_batched = dataset_test.batch(1)\n",
    "dataset_test_prefetched = dataset_test_batched.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 20)                27520     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 27,961\n",
      "Trainable params: 27,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(MAX_FRAMES_PER_VIDEO, FEATURE_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 154.2523 - val_loss: 48.7091\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 34.5535 - val_loss: 39.9486\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 32.0946 - val_loss: 29.0385\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 46s 3s/step - loss: 28.9406 - val_loss: 28.9143\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2227 - val_loss: 29.1197\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1768 - val_loss: 28.8463\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1276 - val_loss: 28.8877\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1364 - val_loss: 28.8633\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1281 - val_loss: 28.8653\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 49s 4s/step - loss: 28.1327 - val_loss: 28.8658\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1330 - val_loss: 28.8636\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1351 - val_loss: 28.8639\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1364 - val_loss: 28.8628\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1380 - val_loss: 28.8624\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1395 - val_loss: 28.8617\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1410 - val_loss: 28.8611\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1423 - val_loss: 28.8606\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 49s 4s/step - loss: 28.1437 - val_loss: 28.8600\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1451 - val_loss: 28.8595\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1464 - val_loss: 28.8590\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1477 - val_loss: 28.8585\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1490 - val_loss: 28.8580\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.1503 - val_loss: 28.8576\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1516 - val_loss: 28.8571\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 49s 4s/step - loss: 28.1528 - val_loss: 28.8567\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1540 - val_loss: 28.8563\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.1552 - val_loss: 28.8559\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1564 - val_loss: 28.8555\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1576 - val_loss: 28.8551\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1588 - val_loss: 28.8547\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1599 - val_loss: 28.8544\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1611 - val_loss: 28.8540\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1622 - val_loss: 28.8537\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1633 - val_loss: 28.8534\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1644 - val_loss: 28.8563\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.4398 - val_loss: 28.9241\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1904 - val_loss: 28.9040\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1513 - val_loss: 28.8849\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1677 - val_loss: 28.8775\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1608 - val_loss: 28.8831\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 56s 4s/step - loss: 28.1611 - val_loss: 28.8808\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1640 - val_loss: 28.8800\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1641 - val_loss: 28.8804\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1651 - val_loss: 28.8800\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1663 - val_loss: 28.8797\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1672 - val_loss: 28.8795\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 55s 4s/step - loss: 28.1682 - val_loss: 28.8792\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1692 - val_loss: 28.8790\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1702 - val_loss: 28.8788\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1712 - val_loss: 28.8786\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1721 - val_loss: 28.8784\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1731 - val_loss: 28.8782\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 55s 4s/step - loss: 28.1740 - val_loss: 28.8780\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 59s 4s/step - loss: 28.1750 - val_loss: 28.8779\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1759 - val_loss: 28.8777\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1768 - val_loss: 28.8775\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.1778 - val_loss: 28.8774\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1787 - val_loss: 28.8772\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1796 - val_loss: 28.8771\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1805 - val_loss: 28.8769\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1814 - val_loss: 28.8768\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1822 - val_loss: 28.8767\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 55s 4s/step - loss: 28.1831 - val_loss: 28.8766\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 74s 5s/step - loss: 28.1840 - val_loss: 28.8765\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 76s 5s/step - loss: 28.1848 - val_loss: 28.8764\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 63s 4s/step - loss: 28.1857 - val_loss: 28.8763\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 70s 5s/step - loss: 28.1865 - val_loss: 28.8762\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 71s 5s/step - loss: 28.1874 - val_loss: 28.8761\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 72s 5s/step - loss: 28.1882 - val_loss: 28.8760\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 90s 6s/step - loss: 28.1890 - val_loss: 28.8760\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 76s 5s/step - loss: 28.1898 - val_loss: 28.8759\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 81s 6s/step - loss: 28.1906 - val_loss: 28.8758\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 59s 4s/step - loss: 28.1914 - val_loss: 28.8758\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 57s 4s/step - loss: 28.1922 - val_loss: 28.8757\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 56s 4s/step - loss: 28.1930 - val_loss: 28.8757\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1938 - val_loss: 28.8756\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.1946 - val_loss: 28.8756\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.1953 - val_loss: 28.8756\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1961 - val_loss: 28.8756\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.1968 - val_loss: 28.8755\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 52s 4s/step - loss: 28.1976 - val_loss: 28.8755\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1983 - val_loss: 28.8755\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 53s 4s/step - loss: 28.1990 - val_loss: 28.8755\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.1998 - val_loss: 28.8755\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.2005 - val_loss: 28.8755\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.2012 - val_loss: 28.8755\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2019 - val_loss: 28.8755\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 54s 4s/step - loss: 28.2026 - val_loss: 28.8755\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.2033 - val_loss: 28.8755\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 49s 4s/step - loss: 28.2039 - val_loss: 28.8755\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.2046 - val_loss: 28.8756\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2053 - val_loss: 28.8756\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2059 - val_loss: 28.8756\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.2066 - val_loss: 28.8756\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 28.2072 - val_loss: 28.8757\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 51s 4s/step - loss: 28.2079 - val_loss: 28.8757\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2085 - val_loss: 28.8757\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 48s 3s/step - loss: 28.2091 - val_loss: 28.8758\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 52s 4s/step - loss: 28.2097 - val_loss: 28.8758\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 49s 3s/step - loss: 28.2103 - val_loss: 28.8758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train_batched_prefetched, epochs=100, validation_data=dataset_test_batched)#_prefetched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x140d825f8>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457,) (457,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1420e4748>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = np.array([ele for batch in dataset_test_batched.as_numpy_iterator() for ele in batch[0]])\n",
    "y_test = np.array([ele for batch in dataset_test_batched.as_numpy_iterator() for ele in batch[1]])\n",
    "results = model.predict(x_test)\n",
    "results = results.reshape(-1)\n",
    "print(results.shape,y_test.shape)\n",
    "plt.scatter(results, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.562601 17.562601 17.191872 17.562601 17.562601 17.562601 16.626986\n",
      " 17.1574   17.562601 16.626986 17.562601 17.227453 17.178532 16.626986\n",
      " 17.227453 17.562601 16.626986 17.169424 17.562601 17.562601 17.204817\n",
      " 17.562601 17.164083 17.562601 17.208838 17.162666 17.562601 17.166983\n",
      " 17.562601 17.562601 17.16273  17.562601 17.169779 17.163225 17.562601\n",
      " 17.562601 17.562601 17.155544 17.562601 17.562601 17.562601 17.562601\n",
      " 17.562601 17.187971 16.626986 16.626986 17.171968 17.562601 17.16115\n",
      " 17.15199  17.184404 17.188963 17.165762 17.16369  17.562601 17.15232\n",
      " 17.562601 17.562601 17.16363  17.562601 17.562601 17.183458 17.180933\n",
      " 17.562601 17.562601 17.227453 17.562601 17.562601 16.626986 17.227453\n",
      " 17.186228 18.066092 17.562601 17.562601 17.562601 16.626986 17.562601\n",
      " 17.562601 16.626986 17.167887 17.562601 17.562601 17.163313 17.170986\n",
      " 17.206907 17.562601 17.562601 17.562601 16.626986 17.562601 17.166933\n",
      " 17.184433 17.164667 17.165201 17.562601 17.165178 17.174171 17.160416\n",
      " 17.18818  17.158728 17.562601 17.562601 17.18882  17.227453 17.227453\n",
      " 17.152946 17.562601 17.152391 17.562601 17.152372 16.626986 17.562601\n",
      " 17.227453 17.165228 17.176758 17.16989  17.562601 17.170122 17.562601\n",
      " 17.167566 17.165676 17.562601 17.562601 17.160555 17.165289 17.173918\n",
      " 17.168087 17.204903 17.562601 17.169954 17.562601 17.562601 16.626986\n",
      " 17.562601 17.179335 16.626986 17.206406 17.161568 17.562601 17.562601\n",
      " 16.626986 17.562601 17.172338 17.182295 17.189737 17.562601 17.227453\n",
      " 17.157085 17.562601 17.165335 17.171055 17.562601 17.562601 17.227453\n",
      " 18.455261 17.562601 17.562601 17.562601 17.158466 17.161211 17.155323\n",
      " 17.562601 17.562601 17.18615  17.227453 17.159466 17.176003 17.562597\n",
      " 17.167145 17.562601 17.562601 17.562601 17.183947 17.562601 16.626986\n",
      " 17.16473  16.626986 17.187777 17.224392 17.562601 17.169127 17.562601\n",
      " 17.562601 17.16917  17.190277 17.562601 17.562601 17.562601 16.626986\n",
      " 17.206717 17.562601 17.16011  17.562601 17.562601 17.562601 17.193249\n",
      " 17.157318 17.163507 17.21519  16.626986 17.16424  16.626986 17.154469\n",
      " 17.208445 17.153143 16.626986 17.180454 17.200235 16.626986 17.160952\n",
      " 17.562601 16.626986 17.562601 16.626986 17.165653 17.227453 17.562601\n",
      " 17.562601 17.562601 17.175592 17.159136 17.165033 17.562601 17.562601\n",
      " 17.562601 17.165806 17.562601 17.157034 17.162792 17.19324  17.562601\n",
      " 17.562601 17.562601 17.152082 18.416319 17.562601 17.188992 17.562601\n",
      " 17.16464  17.15735  17.562601 17.562601 17.562601 17.173473 16.626986\n",
      " 17.18261  17.562601 17.227453 17.15994  17.173746 17.171722 17.165369\n",
      " 16.626986 16.626986 17.562601 17.562601 17.562601 17.150099 17.562601\n",
      " 17.562601 17.173668 17.562601 17.562601 17.165396 17.18292  17.151123\n",
      " 17.227453 17.562601 17.562601 17.562601 17.562601 17.562601 17.169926\n",
      " 17.562601 17.160006 17.167719 17.562601 17.178236 17.15965  17.562601\n",
      " 17.227453 17.562601 16.626986 17.562601 17.562601 17.208403 17.562601\n",
      " 17.562601 17.153091 17.562601 17.162687 17.163189 17.17298  17.562601\n",
      " 17.16982  17.562601 16.626986 17.562601 17.157595 17.169413 17.172909\n",
      " 17.562601 17.562601 17.562601 16.626986 17.562601 17.562601 17.18255\n",
      " 17.562601 17.562601 17.562601 17.562601 17.166204 17.168095 17.562601\n",
      " 17.163984 17.166008 17.562601 17.227453 17.175282 17.180721 17.562601\n",
      " 16.626986 17.562601 17.562601 17.186415 17.562601 17.165949 17.16455\n",
      " 17.163456 17.158228 17.562601 16.626986 17.170435 17.179575 17.562601\n",
      " 17.163437 16.626986 17.162271 17.227453 16.626986 17.16497  17.562601\n",
      " 17.158213 17.1648   17.200129 17.562601 17.172731 16.626986 17.562601\n",
      " 17.562601 17.562601 17.562601 17.162113 17.562601 17.179945 17.17273\n",
      " 17.562601 17.562601 17.174803 17.180141 16.626986 17.158398 17.562601\n",
      " 17.162693 17.562601 17.562601 17.562601 17.562601 17.169874 17.562601\n",
      " 17.562601 17.562601 17.562601 17.182251 17.170412 17.239155 17.176798\n",
      " 17.562601 12.0092   17.562601 17.227453 17.562601 17.169123 17.151037\n",
      " 17.562601 17.227453 17.163383 17.16291  17.179508 17.562601 17.562601\n",
      " 16.626986 17.562601 17.562601 17.15165  17.158415 16.626986 17.562601\n",
      " 17.562601 16.626986 17.193987 17.562601 17.562601 17.562601 17.562601\n",
      " 17.562601 17.19732  17.163406 17.168423 17.178082 17.562601 17.152061\n",
      " 17.17129  17.562601 17.20317  17.562601 17.562601 17.562601 17.562601\n",
      " 17.562601 17.189896 16.821503 17.171839 17.562601 17.165428 17.562601\n",
      " 17.169086 17.175207 17.562601 16.626986 17.562601 16.626986 17.17607\n",
      " 17.562601 17.562601 17.562601 17.173859 17.562601 17.562601 16.626986\n",
      " 17.562601 16.626986 17.159819 17.562601 17.562601 17.208838 16.626986\n",
      " 17.16466  17.562601 17.562601 17.562601 17.169094 17.562601 17.562601\n",
      " 17.562601 17.191992] [15.25767773 15.67954135 13.41349027 13.71877862 13.3266373  11.10745677\n",
      " 22.48975163 15.19861311 21.81117698 15.11256427 14.56862781 15.72933577\n",
      " 12.39092306 23.78861482 17.37955811 15.6008632  19.2217641  11.25394176\n",
      " 32.69874707 14.11482468 14.27682266  9.82021498 14.69126742 20.64907086\n",
      " 12.81411368 17.32597918 17.11852321 14.66042587 19.49086653 16.17511971\n",
      " 17.04481742 32.69874707 18.21638173 32.69874707 17.69925385 27.53660344\n",
      " 12.50886883 19.88969327 18.31238207 15.81824971 14.99999453 13.55977735\n",
      " 15.49801771 20.84967434 14.65763672 10.69761461 17.21342829 13.1631698\n",
      " 21.77308335  9.34309399 17.65559991 19.73529776 19.66246051 17.11710454\n",
      " 25.26888678 13.74098646 13.41152284 18.21107512 12.55177693 24.14840377\n",
      " 13.63100089 21.12022996 17.53732349 13.56792554 12.82026877 14.9950617\n",
      " 16.51264566 14.54505773 16.07990943 13.74192384 22.69129608 14.54364397\n",
      " 12.91227481 25.35754543 19.16670427 16.23257982 12.23992565 13.14306708\n",
      " 13.93622391 11.28094728 15.24083195 18.43138293 12.82447171 12.27811001\n",
      " 19.74827043 20.16709113 10.85947304 21.41215898 16.78871239 21.74342163\n",
      " 12.87484064 12.92910363 17.28044111 11.42823362 19.27205665 13.02636285\n",
      " 14.91416324 18.00738149 14.35312612 13.99903275 15.38098857 18.51419595\n",
      " 16.6516789  17.86581797 16.25518735 24.11782922 14.36457649 10.56205352\n",
      " 14.60112231 15.3481433  22.52974908 31.18583123 15.93904236 18.92606473\n",
      " 23.59329712 10.85679493 14.74254255 12.00992972 19.56048529 32.69874707\n",
      " 18.48380598 17.46581313 16.30432354 16.83856281 15.09934391 15.69998986\n",
      " 13.39906664 17.10947589 14.66598889 18.19780524 22.83641641 14.50470329\n",
      " 22.13694453 12.25210648 15.16886003 12.93395587 13.19649512 24.16962475\n",
      " 17.14615566 10.73164461 24.3118393  19.40378617 18.22728944 13.261654\n",
      " 13.1724999   9.         19.04003544 27.28141846 22.24165234 10.67257885\n",
      " 15.50217014 14.94831334 15.88290131 21.88809641 11.27936244  9.79536308\n",
      " 17.93043676 15.93287836 28.86646505 16.13355073 14.21398445 32.69874707\n",
      " 10.29215615 17.30257077 16.33088121 13.71162222 17.61844462 23.03389615\n",
      " 14.99451481 18.28610568 32.69874707 16.41169475 11.42125088 14.49054205\n",
      " 22.0226837  14.99466857 13.42555416 17.80246517 15.18356369 22.35896617\n",
      " 12.90616878 21.64976389 20.92481484 11.25825052 13.09710416 11.79419748\n",
      " 10.66954117 24.79020247 26.80730388 22.52192352 13.03619126 20.29075716\n",
      " 15.81535249 18.18960412 26.28020941 21.45130759 21.11743264 16.93862859\n",
      " 14.39271449 10.55571023 18.55993012 13.69669044 15.50639008 14.33431535\n",
      " 11.88556596 12.50452889 20.09142503 12.57446128 14.36133942 17.64816286\n",
      " 20.47497407 12.64079399 18.03811647 12.27772939 10.85443977 16.03765176\n",
      " 18.06913054 29.21350136 14.17787019 12.13546033 13.82483272 19.19863396\n",
      " 25.24632456 32.69874707 15.31339021 22.10731307 20.07871888 11.11470234\n",
      " 15.44475966 20.24596436 13.98633152 11.02441555 23.06432998 19.8135482\n",
      " 15.03941236 18.48934169 24.48737998 18.06868099 15.48074619 14.24181647\n",
      " 15.42649635 13.6253921  16.26649299 14.16543623 19.19507694 10.67752461\n",
      " 21.78177423 17.07773595 12.37496551 18.39379302 11.20675821 15.94446329\n",
      " 11.71859359 13.4475946  17.95511878 18.06759079 10.25261639 15.58252047\n",
      " 12.08288087 12.82486105 11.36627458 18.71163112  9.73335614 10.97013213\n",
      " 15.29934093 10.30499956 26.00684222 18.81809205 20.59940615 18.54527454\n",
      " 17.40194779 19.91115032 10.73047067 22.35727104 21.90335143 19.35787336\n",
      " 26.55049188 30.39504223 15.02137876 18.65607484 32.69874707 14.02477529\n",
      " 16.30139322 13.37675389 22.6220967  11.07908418 21.37800405 12.82339793\n",
      " 19.3617299  19.0523206  14.84441511 14.95071455 20.23156271 13.93605863\n",
      " 25.82675384 12.03861307 13.95532398 32.69874707 10.69245891 19.09634171\n",
      " 22.55719716 20.86507151 13.32032823 12.87026086 11.52635741 17.54828466\n",
      " 31.51948332 12.2289681  10.20431374 30.9225488  17.18162612 12.48976359\n",
      " 11.9235051  16.9175297   9.24059176 20.21660183 12.5835583  25.99284729\n",
      " 16.61182888 17.37032211 15.02725787 14.86985161 20.81618798 16.18978662\n",
      " 27.96834536 19.9073669  14.34900099 15.17431531 10.5494849  30.28033827\n",
      "  9.97722096 30.77774242 28.62028215 15.21860277 15.83180256 12.08881755\n",
      " 16.12202444 14.1130937  16.28960098 15.36454212 16.31438319 17.01057093\n",
      " 24.67661788 11.36044413 10.47026705 26.55185659 10.03836018 32.69874707\n",
      " 13.15420156 12.41299363 18.70667181 15.53144233 24.58696939 22.46677062\n",
      " 16.13075122 10.34935004  9.55630642 10.88335467 32.69874707 17.27108189\n",
      " 13.27138682 28.80049278 12.95504209 26.438518   10.68086639 21.09876205\n",
      "  9.48860081 26.26477646 14.46625498 14.24706265 23.13747788 18.32570002\n",
      " 12.74131088 15.44020526 14.81313288 11.32780457 15.50748568  9.44033111\n",
      " 15.14461566 11.02749072 17.99458025 32.69874707 14.94193986 11.80186989\n",
      " 14.02952405 13.8027064  16.86922275 17.24750738 11.86797135 18.34766945\n",
      " 22.23434039 17.00687232 15.85713015 32.69874707 17.79492927 14.05777312\n",
      " 23.007738   19.46507018 27.35418459  9.55057342 15.16049922 11.02836007\n",
      " 14.5922692  12.17846054 18.26552909 13.51307106 26.96385341 16.89547355\n",
      " 17.07140868 16.66231048 21.40207227 17.72258752 16.22188563 12.46979134\n",
      " 13.05644064 12.97401808 18.50966242 18.72926282 19.95512719 14.6881153\n",
      " 16.5606518  16.55020575 19.67665096 16.35371414 17.21488184 10.00799499\n",
      " 25.76077913 22.51833312 11.16051349 14.12848305 29.83503006 32.69874707\n",
      " 14.50393146 19.42086673 13.95619962 16.73288534 19.59531714 18.06938661\n",
      " 24.08681594 22.12768527 12.65569954 16.59739306 10.1410847  19.14149604\n",
      " 14.56829918 10.06896033 32.69874707 14.57360648 22.56166764 13.93780334\n",
      " 20.88856947 15.66274175 20.65176612 16.75093038 19.34742439 20.56166259\n",
      " 12.2468327 ]\n"
     ]
    }
   ],
   "source": [
    "print(results, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=28.722319>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.MSE(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
