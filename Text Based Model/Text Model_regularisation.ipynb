{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas) (2.7.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.18.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/kldsouza/Library/Python/3.7/lib/python/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (42.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.22)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from nltk) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.7.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install bs4\n",
    "!pip install nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all', quiet = True)\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "   \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "   \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "   \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "   \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "   \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "   \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "   \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "   \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "   \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "   \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "   \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "   \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "   \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "   \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "   \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "   \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "   \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed_video/audio_xCgk9nvuCxk_txt failed processing\n",
      "./processed_video/audio_Q_ouhkdo-ko_txt failed processing\n",
      "\n",
      "Shape of raw_inputs:  (3389,)\n",
      "Shape of labels:  (3389,)\n",
      "Max Words:  84\n",
      "Max Frames:  186\n",
      "Max Sequence Lenghth:  1500\n"
     ]
    }
   ],
   "source": [
    "# Read all the data\n",
    "labels = []\n",
    "raw_inputs = []\n",
    "df = pd.read_csv('./raw_data.csv')\n",
    "max_frames = 0\n",
    "max_words = 0\n",
    "max_sequence_length = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    path = os.path.join('./processed_video', 'audio_' + row['video_id'] + '_txt')\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                raw_inputs_video = []\n",
    "                sequence_length = 0\n",
    "                file_data = json.load(f)\n",
    "                num_frames = len(file_data)\n",
    "                \n",
    "                if num_frames > max_frames:\n",
    "                    max_frames = num_frames\n",
    "\n",
    "                for i in range(num_frames):\n",
    "                    line_data = json.loads(file_data[i])\n",
    "\n",
    "                    if 'DisplayText' in line_data.keys():\n",
    "                        sentence = line_data['DisplayText']\n",
    "                        cleaned_sentence = text_cleaner(sentence)\n",
    "                        num_words = len(cleaned_sentence.split())\n",
    "                        sequence_length = sequence_length + num_words\n",
    "\n",
    "                        if num_words > max_words:\n",
    "                            max_words = num_words\n",
    "                        raw_inputs_video.append(cleaned_sentence)\n",
    "\n",
    "                    del line_data\n",
    "                \n",
    "                raw_inputs.append(raw_inputs_video)\n",
    "                labels.append((row['video_likeCount'] - row['video_dislikeCount'])/row['video_viewCount'])\n",
    "                \n",
    "                if sequence_length > max_sequence_length:\n",
    "                    max_sequence_length = sequence_length\n",
    "\n",
    "                del raw_inputs_video, file_data, sequence_length\n",
    "            except ValueError:\n",
    "                print(path + ' failed processing')\n",
    "\n",
    "raw_inputs = np.array(raw_inputs)\n",
    "labels = np.array(labels)\n",
    "print()\n",
    "print('Shape of raw_inputs: ', raw_inputs.shape)\n",
    "print('Shape of labels: ', labels.shape)\n",
    "print('Max Words: ', max_words)\n",
    "print('Max Frames: ', max_frames)\n",
    "print('Max Sequence Lenghth: ', max_sequence_length)\n",
    "np.save('./text.npy', raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.021500000000000002, -0.0122]       1\n",
      "(-0.0122, -0.00398]                    7\n",
      "(-0.00398, 0.00421]                  225\n",
      "(0.00421, 0.0124]                   1094\n",
      "(0.0124, 0.0206]                    1021\n",
      "(0.0206, 0.0288]                     613\n",
      "(0.0288, 0.037]                      264\n",
      "(0.037, 0.0452]                      103\n",
      "(0.0452, 0.0533]                      31\n",
      "(0.0533, 0.0615]                      17\n",
      "(0.0615, 0.0697]                       5\n",
      "(0.0697, 0.0779]                       2\n",
      "(0.0779, 0.0861]                       1\n",
      "(0.0861, 0.0943]                       1\n",
      "(0.0943, 0.102]                        0\n",
      "(0.102, 0.111]                         1\n",
      "(0.111, 0.119]                         1\n",
      "(0.119, 0.127]                         0\n",
      "(0.127, 0.135]                         1\n",
      "(0.135, 0.143]                         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_series = pd.Series(labels)\n",
    "print(label_series.value_counts(bins=20).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for cnn lstm by concatenating frames, normalizing labels and defining constants\n",
    "text_inputs = [''.join(row) for row in raw_inputs]\n",
    "labels = np.clip(labels, 0.00421, 0.037)\n",
    "min_label = np.min(labels)\n",
    "max_label = np.max(labels)\n",
    "scaled_labels = (labels - min_label)/(max_label - min_label)\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = max_sequence_length\n",
    "VALIDATION_SPLIT = 0.3\n",
    "GLOVE_DIR = './glove.twitter.27B'\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121402 unique tokens.\n",
      "Shape of data tensor: (3389, 1500)\n",
      "Shape of label tensor: (3389,)\n",
      "Shape of training tensor: (2373, 1500)\n",
      "Shape of training labels: (2373,)\n",
      "Shape of testing tensor: (1016, 1500)\n",
      "Shape of testing labels: (1016,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(text_inputs)\n",
    "sequences = tokenizer.texts_to_sequences(text_inputs)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', scaled_labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = scaled_labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "print('Shape of training tensor:', x_train.shape)\n",
    "print('Shape of training labels:', y_train.shape)\n",
    "print('Shape of testing tensor:', x_val.shape)\n",
    "print('Shape of testing labels:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.twitter.27B.200d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1500, 200)         24280600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1496, 128)         128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 55, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 24,589,465\n",
      "Trainable params: 308,865\n",
      "Non-trainable params: 24,280,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2373 samples, validate on 1016 samples\n",
      "Epoch 1/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.1649 - root_mean_squared_error: 0.4060 - val_loss: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 2/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.0866 - root_mean_squared_error: 0.2942 - val_loss: 0.0780 - val_root_mean_squared_error: 0.2794\n",
      "Epoch 3/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.0823 - root_mean_squared_error: 0.2869 - val_loss: 0.0761 - val_root_mean_squared_error: 0.2759\n",
      "Epoch 4/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.0810 - root_mean_squared_error: 0.2847 - val_loss: 0.0762 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 5/10\n",
      "2373/2373 [==============================] - 23s 10ms/sample - loss: 0.0806 - root_mean_squared_error: 0.2840 - val_loss: 0.0761 - val_root_mean_squared_error: 0.2758\n",
      "Epoch 6/10\n",
      "2373/2373 [==============================] - 25s 11ms/sample - loss: 0.0798 - root_mean_squared_error: 0.2824 - val_loss: 0.0765 - val_root_mean_squared_error: 0.2765\n",
      "Epoch 7/10\n",
      "2373/2373 [==============================] - 22s 9ms/sample - loss: 0.0796 - root_mean_squared_error: 0.2821 - val_loss: 0.0762 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 8/10\n",
      "2373/2373 [==============================] - 22s 9ms/sample - loss: 0.0793 - root_mean_squared_error: 0.2816 - val_loss: 0.0762 - val_root_mean_squared_error: 0.2761\n",
      "Epoch 9/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.0791 - root_mean_squared_error: 0.2812 - val_loss: 0.0761 - val_root_mean_squared_error: 0.2758\n",
      "Epoch 10/10\n",
      "2373/2373 [==============================] - 21s 9ms/sample - loss: 0.0793 - root_mean_squared_error: 0.2816 - val_loss: 0.0772 - val_root_mean_squared_error: 0.2778\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-12, l2=1.e-12))(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-12, l2=1.e-12))(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-12, l2=1.e-12))(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(1, activation='linear')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# happy learning!\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3Scd53f8fd3ZnS3ZmxLcuIZO7EhTrCkkAuOCZcNtwIOtAkcIASaLtnTNpzTpqV7CiW0EAp7epqepTRwNlwCG/aw2ZCTDXRJi1mSQMKlhMVOyAbfYjvBiWU7tnyRLcnWZWa+/eN5JI1kyR7ZIz2jZz6vc3Rmnqu+M7Y+v2d+zzO/x9wdERGJr0TUBYiIyNxS0IuIxJyCXkQk5hT0IiIxp6AXEYm5VNQFTNXe3u6rVq2KugwRkQXl6aefPuzuHdMtq7qgX7VqFZs3b466DBGRBcXMXpppmbpuRERiTkEvIhJzCnoRkZiruj56EZFzMTo6Sk9PD0NDQ1GXMqcaGxtZsWIFdXV1ZW+joBeRWOjp6aG1tZVVq1ZhZlGXMyfcnSNHjtDT08Pq1avL3k5dNyISC0NDQ7S1tcU25AHMjLa2tll/alHQi0hsxDnkx5zLa4xN0PedHOErj+/i9z3Hoy5FRKSqxCbokwnjfz2+k5/vPBR1KSJSg/r6+vja17426+3e85730NfXNwcVTYhN0Lc21rGqrZkt+05EXYqI1KCZgj6fz59xu40bN7J48eK5KguI2VU3XbkMz/XMbcsoIjKdO+64gxdeeIErr7ySuro6GhsbWbJkCTt27GDnzp28733vY+/evQwNDfGJT3yC2267DZgY9mVgYIDrr7+eN7/5zfz6178ml8vxwx/+kKampvOuLVZB353N8KPnDnD85CiZ5vKvMRWRePnC/9nKtv2V/XTfmU3z+X/WNePyu+66iy1btvDss8/y5JNP8t73vpctW7aMXwZ53333sXTpUk6dOsU111zDBz7wAdra2ibtY9euXXzve9/jW9/6FjfddBPf//73ueWWW8679th03QB0ZdMAbN2vE7IiEq3169dPutb9q1/9KldccQXXXnste/fuZdeuXadts3r1aq688koAXve617Fnz56K1BKrI/qJoD/BGy9pj7gaEYnKmY6850tLS8v48yeffJLHH3+cp556iubmZt761rdOey18Q0PD+PNkMsmpU6cqUkusjujbFjWQzTSyRUf0IjLPWltb6e/vn3bZ8ePHWbJkCc3NzezYsYPf/OY381pbrI7oATqzGbbsU9CLyPxqa2vjTW96E93d3TQ1NXHBBReML9uwYQPf+MY3WLt2LZdddhnXXnvtvNZWVtCb2QbgK0AS+La73zVl+XXA3cBrgZvd/eGSZRcB3wZWAg68x933VKT6aXTn0vx0x0FOjuRpro9dOyYiVeyBBx6Ydn5DQwM//vGPp1021g/f3t7Oli1bxud/8pOfrFhdZ+26MbMkcA9wPdAJfMTMOqes9jJwKzDdq/wu8OfuvhZYD8zpN5q6sxncYfsBXU8vIgLl9dGvB3a7+4vuPgI8CNxYuoK773H354Bi6fywQUi5+2PhegPufrIypU+vKxeckNUXp0REAuUEfQ7YWzLdE84rx6VAn5n9wMx+Z2Z/Hn5CmMTMbjOzzWa2ube3t8xdT+/CdCNtLfW6xFJEJDTXV92kgD8CPglcA7yKoItnEne/193Xufu6jo5pb2JeNjOjM5vWEb2ISKicoN9HcCJ1zIpwXjl6gGfDbp888HfA1bMrcfa6cxl2HuxnOF+Y618lIlL1ygn6TcAaM1ttZvXAzcAjZe5/E7DYzMYO098ObJt9mbPTnc2QLzq7Dg7M9a8SEal6Zw368Ej8duAnwHbgIXffamZfNLMbAMzsGjPrAT4EfNPMtobbFgi6bX5qZr8HDPjW3LyUCWPfkNX19CIyX851mGKAu+++m5Mn5+46lbL66N19o7tf6u6vdvf/Fs67090fCZ9vcvcV7t7i7m3u3lWy7WPu/lp3v9zdbw2v3JlTFy1tprUhpW/Iisi8qeagj+U3ihKJ4ITs1gqPXiciMpPSYYrf+c53smzZMh566CGGh4d5//vfzxe+8AUGBwe56aab6OnpoVAo8LnPfY6DBw+yf/9+3va2t9He3s4TTzxR8dpiGfQAXdkMD/z2JQpFJ5mI/30kRaTEj++AV35f2X1eeDlcf9eMi0uHKX700Ud5+OGH+e1vf4u7c8MNN/CLX/yC3t5estksP/rRj4BgDJxMJsOXv/xlnnjiCdrb52YwxlgNalaqO5dmaLTIi706ISsi8+vRRx/l0Ucf5aqrruLqq69mx44d7Nq1i8svv5zHHnuMT3/60/zyl78kk8nMSz2xPaLvzgVv4Jb9x1lzQWvE1YjIvDrDkfd8cHc+85nP8PGPf/y0Zc888wwbN27ks5/9LO94xzu4884757ye2B7Rv6q9hYZUQl+cEpF5UTpM8bvf/W7uu+8+BgaCHoV9+/Zx6NAh9u/fT3NzM7fccguf+tSneOaZZ07bdi7E9og+lUywdnlaQyGIyLwoHab4+uuv56Mf/ShveMMbAFi0aBH3338/u3fv5lOf+hSJRIK6ujq+/vWvA3DbbbexYcMGstnsnJyMNXev+E7Px7p163zz5s0V2ddn/+73/PB3+/nHz7+LhE7IisTa9u3bWbt2bdRlzIvpXquZPe3u66ZbP7ZdNxBcedM/nGfvsTkdMFNEpKrFOui7s8EJWV1PLyK1LNZBf+mFi0glTEMhiNSIauuKngvn8hpjHfQNqSRrLmhli47oRWKvsbGRI0eOxDrs3Z0jR47Q2Ng4q+1ie9XNmO5smp/tOIS7Y6YTsiJxtWLFCnp6ejjfmxdVu8bGRlasWDGrbeIf9LkMf/t0DwdPDHNhZnatoIgsHHV1daxevTrqMqpSrLtuQEMWi4jEPujXLk9jpitvRKR2xT7oWxpSvKq9RWPTi0jNin3QQ/DFqa3quhGRGlUTQd+dS7P/+BBHB+f85lYiIlWnNoJ+/BuyOqoXkdpTE0HfOX7ljU7IikjtqYmgX9xcz4olTTqiF5GaVBNBD8H19LrEUkRqUc0EfXc2wx8OD9I/NBp1KSIi86p2gj68h+z2A3N3uy4RkWpUM0GvoRBEpFbVTNAvSzfS0dqgfnoRqTk1E/QQDFmsK29EpNbUVNB3ZTPsOjTA0Ggh6lJEROZNTQV9dy5Noeg8/4pOyIpI7aipoO8Kh0LQSJYiUktqKuhXLGki01SnoRBEpKbUVNCbGV3ZNNt0RC8iNaSmgh6CL05tf6Wf0UIx6lJEROZFzQV9VzbNSL7I7kMDUZciIjIvajDox8amVz+9iNSGsoLezDaY2fNmttvM7phm+XVm9oyZ5c3sg9MsT5tZj5n9RSWKPh+r21tork9qKAQRqRlnDXozSwL3ANcDncBHzKxzymovA7cCD8ywmz8DfnHuZVZOMmGsXa5vyIpI7SjniH49sNvdX3T3EeBB4MbSFdx9j7s/B5x2htPMXgdcADxagXorojubZtv+ExSLHnUpIiJzrpygzwF7S6Z7wnlnZWYJ4H8Cn5x9aXOnK5dhcKTAniODUZciIjLn5vpk7L8BNrp7z5lWMrPbzGyzmW3u7e2d45JKhizWCVkRqQHlBP0+YGXJ9IpwXjneANxuZnuALwF/bGZ3TV3J3e9193Xuvq6jo6PMXZ+7NctaqU8m1E8vIjUhVcY6m4A1ZraaIOBvBj5azs7d/Z+PPTezW4F17n7aVTvzrT6V4LILW9mqoRBEpAac9Yje3fPA7cBPgO3AQ+6+1cy+aGY3AJjZNWbWA3wI+KaZbZ3LoiuhK5tmy/7juOuErIjEWzlH9Lj7RmDjlHl3ljzfRNClc6Z9/BXwV7OucI505TI8uGkv+48PkVvcFHU5IiJzpua+GTumW/eQFZEaUbNB/5oL0yQMtiroRSTmajbom+qTXLJskca8EZHYq9mgh2CAM91tSkTirsaDPs3BE8P09g9HXYqIyJyp6aDvzo0NWayjehGJr5oO+s7wyhv104tInNV00Kcb67i4rVlH9CISazUd9ADd2QxbNBSCiMRYzQd9ZzbNy0dPcvzUaNSliIjMiZoP+rETstvUTy8iMVXzQd81fkJW/fQiEk81H/Ttixq4MN2oMW9EJLZqPugBunNpXWIpIrGloCcYCuGF3gFOjuSjLkVEpOIU9AT99EWH7Qf6oy5FRKTiFPSUXnmjfnoRiR8FPbA808jSlnp9cUpEYklBD5jZ+D1kRUTiRkEf6spm2Hmwn5F8MepSREQqSkEf6s6lGS04Ow/qhKyIxIuCPtSV1dj0IhJPCvrQxUubWdSQ0henRCR2FPShRMLozKY1FIKIxI6CvkRXNs32A/0Uih51KSIiFaOgL9GdzXBqtMAfDg9EXYqISMUo6EuMfUNWX5wSkThR0Jd4dUcLDamErrwRkVhR0JdIJRO8ZnlaR/QiEisK+im6s2m27j+Ou07Iikg8KOin6MpmODGUp+fYqahLERGpCAX9FN254B6yup5eROJCQT/FpRe0kkyYRrIUkdhQ0E/RWJdkzbJFGgpBRGJDQT+N7lyGLft0QlZE4kFBP42ubJrDAyMc6h+OuhQRkfNWVtCb2QYze97MdpvZHdMsv87MnjGzvJl9sGT+lWb2lJltNbPnzOzDlSx+rox9Q1ZfnBKRODhr0JtZErgHuB7oBD5iZp1TVnsZuBV4YMr8k8Afu3sXsAG428wWn2/Rc23t8jRmGgpBROIhVcY664Hd7v4igJk9CNwIbBtbwd33hMsm3YfP3XeWPN9vZoeADqDvvCufQ4saUqxua9ElliISC+V03eSAvSXTPeG8WTGz9UA98MI0y24zs81mtrm3t3e2u54TXbmMrrwRkViYl5OxZrYc+GvgT9z9tLtvu/u97r7O3dd1dHTMR0ln1Z1Ns6/vFMcGR6IuRUTkvJQT9PuAlSXTK8J5ZTGzNPAj4L+4+29mV150Ju4hq6N6EVnYygn6TcAaM1ttZvXAzcAj5ew8XP9/A99194fPvcz515UNhkLQlTcistCdNejdPQ/cDvwE2A485O5bzeyLZnYDgJldY2Y9wIeAb5rZ1nDzm4DrgFvN7Nnw58o5eSUVtqSlntziJrboiF5EFrhyrrrB3TcCG6fMu7Pk+SaCLp2p290P3H+eNUamK5tmq668EZEFTt+MPYPuXIY/HBlkYDgfdSkiIudMQX8G3bk07rD9gLpvRGThUtCfwfiVN+q+EZEFTEF/BstaG2hf1KATsiKyoCnoz8DM6M6lNRSCiCxoCvqz6Mqm2X1ogKHRQtSliIicEwX9WXRnM+SLzs6D/VGXIiJyThT0ZzE2Nr2GLBaRhUpBfxYrljSRbkxpKAQRWbAU9GdhZnRlM7ryRkQWLAV9GbpzaXYcOEG+cNoIyyIiVU9BX4aubIbhfJEXegejLkVEZNYU9GXozgVDFut6ehFZiBT0ZVjdvoimuiRbdEJWRBYgBX0Zkglj7fJW3W1KRBYkBX2ZunMZtu0/QbHoUZciIjIrCvoydWXTDAzneenoyahLERGZFQV9mSZuFq5+ehFZWBT0Zbr0glbqkqahEERkwVHQl6k+leDSC1p1RC8iC46Cfha6sxm27j+Bu07IisjCoaCfhe5cmqODIxw4PhR1KSIiZVPQz0JndmzIYnXfiMjCoaCfhbXLW0kY+uKUiCwoCvpZaK5P8eqORTohKyILioJ+lrqyaR3Ri8iCoqCfpe5chgPHhzg8MBx1KSIiZVHQz9LEN2R1VC8iC4OCfpY6s8HY9OqnF5GFQkE/S5mmOi5a2sxWDYUgIguEgv4cdOfSugmJiCwYCvpz0JXN8NKRk5wYGo26FBGRs1LQn4OusJ9+m07IisgCoKA/B10aCkFEFhAF/TnoaG3ggnSDjuhFZEFQ0J+j7mxGJ2RFZEEoK+jNbIOZPW9mu83sjmmWX2dmz5hZ3sw+OGXZx8xsV/jzsUoVHrWuXIbdhwY4NVKIuhQRkTM6a9CbWRK4B7ge6AQ+YmadU1Z7GbgVeGDKtkuBzwOvB9YDnzezJedfdvS6smmKDjteUfeNiFS3co7o1wO73f1Fdx8BHgRuLF3B3fe4+3NAccq27wYec/ej7n4MeAzYUIG6I9edC0/Iqp9eRKpcOUGfA/aWTPeE88pR1rZmdpuZbTazzb29vWXuOlrZTCNLmuvYqitvRKTKVcXJWHe/193Xufu6jo6OqMspi5nRFd5DVkSkmpUT9PuAlSXTK8J55TifbateVy7N86/0M5Kf2mMlIlI9ygn6TcAaM1ttZvXAzcAjZe7/J8C7zGxJeBL2XeG8WOjKZhgpFNl1qD/qUkREZnTWoHf3PHA7QUBvBx5y961m9kUzuwHAzK4xsx7gQ8A3zWxruO1R4M8IGotNwBfDebHQPT5ksbpvRKR6pcpZyd03AhunzLuz5Pkmgm6Z6ba9D7jvPGqsWqvaWmipTwYnZNetPPsGIiIRqIqTsQtVImF0ZtO6xFJEqpqC/jx1ZTNsP3CCQtGjLkVEZFoK+vPUnctwcqTAHw4PRl2KiMi0FPTnqUv3kBWRKqegP0+XLFtEfSqhK29EpGop6M9TXTLB2gtbdRMSEalaCvoK6AyHQnDXCVkRqT4K+grozqU5fmqUnmOnoi5FROQ0CvoK6A7vIasTsiJSjRT0FXDZha0kE6YTsiJSlRT0FdBYl2TNskU6ISsiVUlBXyFd2YyGQhCRqqSgr5CubJre/mEOnRiKuhQRkUkU9BUydg9Z9dOLSLVR0FdIZzgUgvrpRaTaKOgrZFFDitXtLTqiF5Gqo6CvoK5smi26ll5EqoyCvoK6cxl6jp2i7+RI1KWIiIxT0FfQ2JDF29R9IyJVREFfQV3hUAjqvhGRaqKgr6ClLfXkFjexZZ+O6EWkeijoK6wzm9bgZiJSVRT0FdadzfDi4UEGh/NRlyIiAkAq6gLi5rUrMrjD2770JG+5tIO3XNbBmy9pZ3FzfdSliUiNUtBX2HWXdvDlm67gZzsO8ei2g/zt0z0kDK5YuTgI/ks7eO2KxSQTFnWpIlIjrNpuf7du3TrfvHlz1GVURKHo/GNPH7/Y2cvPd/by7N4+3GFxcx1/tKaD69a085ZLO1iWboy6VBFZ4MzsaXdfN+0yBf38OTY4wq92H+bnYfD39g8DsHZ5evxo/3UXL6E+pVMnIjI7Cvoq5O7seKU/CP3ne9n80lFGC05LfZI3vLqdt1zWwVsv7WDl0uaoSxWRBUBBvwAMDOd56oUj/HznIX6+s5e9R4Mbjb+qvYXrwqP9a1/VRlN9MuJKRaQaKegXGHdnz5GT/Pz5IPSfevEIQ6NF6lMJXr966Xg3zyXLFmGmk7oioqBf8IZGC2zac3T8pO7OgwMALM80jof+Gy9pJ9NUF3GlIhIVBX3M7O87NR76v9p9mP6hPMmEcfVFwSWc113aQXc2Q0KXcIrUDAV9jOULRZ7d2zd+Jc9zPcHwC20t9axfvZQL0o0sbamnbVE9bS31tC1qCKZb6sk01anrRyQmFPQ15PDAML/adZhf7Ozld3v7ODwwTP/Q9MMxpBLGkpaxBqCepS0NwfPSBmGsgWhpIN2UUsMgUqXOFPT6ZmzMtC9q4H1X5XjfVbnxecP5AscGRzkyOMzRwRGODIxwZHCEIwPB9OGBEY4ODvP7Y30cGRihf4ZxeuqSxpLmoBFoa6mf8ZPC2PN0oxoGkWpQVtCb2QbgK0AS+La73zVleQPwXeB1wBHgw+6+x8zqgG8DV4e/67vu/t8rWL+UoSGV5MJMkgsz5X0DdzhfmNQgHB0cnng+MMKRwWGODI7w8tGTHB0cYeAMDUMQ+HXUpxLUJRPUpxLUh491SaM+lQwex+dNPDaMrZNMUDdpu8SUeUZ9MkldKly35PeMrVOXNDU6UrPOGvRmlgTuAd4J9ACbzOwRd99Wstq/BI65+yVmdjPwP4APAx8CGtz9cjNrBraZ2ffcfU+lX4hUTkMqyfJME8szTWWtPzQaNAzBp4PhkudBI3HiVJ7RQpGRQpGRfJGTI3n6ThUZzfv4vLHlo/nwsVD5LsWmuiStjanwp47WxhTp8LF0XmvpvIbJy/WtZVmIyjmiXw/sdvcXAczsQeBGoDTobwT+a/j8YeAvLDh8cqDFzFJAEzAC6K4cMdNYlyS7uIns4vIahnK4+3jgjzcE443AROMwnJ+8zsS84uTt8kVOjhToH8rTPzxK/1CeE0N59vWdCuYNjTI0WjxrXQ2pBK2NdaRPaxxObyjSMzQe9cmEPl3IvCon6HPA3pLpHuD1M63j7nkzOw60EYT+jcABoBn4U3c/OvUXmNltwG0AF1100SxfgsSRmdGQStKQAhrm53eOFooMDOXDRmB0vAGY9DgcPD8Rrtc/NMorJ4bGl58cKZT1u8wgaUbCjEQifJ4IppPjjwTLw3nJhI1vN7ZO6baT9je2fLr9heumwm6xVNJIJYLurlTCqAu7ulJhN1hdMpg3sSwxadvx9RNT1k9Os/7461BDN5/m+mTseqAAZIElwC/N7PGxTwdj3P1e4F4IrrqZ45pEplWXTLCkpZ4lLed+74B8ocjA8NTGYqKhGBjOM5IvUnSn6E6hSPgYTBeLTiGc7+H8Qji/6Iw/L4TTk7Yde14MGq2z7W+04OSLwSei0UKR/Nhjce7/BCcamIlGLDnWWE19Pj6P0+aNbT+1QSudd+ZtIJEwDBt//8bez7HHfGHiPSs44+9/YdL7O7Hu+H5K1i1Oee/zxcn/NmPLL89luP9fTT2OPn/lBP0+YGXJ9Ipw3nTr9ITdNBmCk7IfBf7e3UeBQ2b2/4B1wIuIxFAqmWBxc/2CvtGMe0kjkHdGixONwGihpGEoTp6Xn7RsYtvR/Ni6Yw1KkZFw/XxJaBYK04dnEL6TG7WxQB7JF6dsw/jzSfuZEqr5QjFoOMP5OJM/HU1pGEo/VSVsSkMSPk8lxtZP0JAaa1wmrzv+aSoxfSM2V4MYlhP0m4A1ZraaINBvJgjwUo8AHwOeAj4I/Mzd3cxeBt4O/LWZtQDXAndXqvhJ8sOw+/FwwoLPxqWPUDKvdJ0Z1j/Tskn7Kt1nuH6yDtI5aFpSsh+RhcHMgiuZSMDCba+kxFmDPuxzvx34CcHllfe5+1Yz+yKw2d0fAf6SIMx3A0cJGgMIrtb5jpltJYjC77j7c3PxQhg6AQ9ObX8iVt8Kiy+CJRcHj4svnjzdmIm6QhGpAfH5ZmxhFA5tA3fASx7HVvDTl8E0659tGSX7nWH9wggc3wd9L0Hfy3DspeD5yMDkmhsXlwT/xac3BPUts38fRGThcA9y4dSx4AeD5a89p13Vxjdjk3Ww/Iqoq5iZe/AP2fdSGPwvTzQEvTth1+OQPzV5m+b2aT4RXBxMZ1ZCnW5BKFIVikUYPjER2KeOwqm+kukz/BRLvnCYWwf/+qcVLy8+QV/tzKB5afCTver05e4w2Dtx9F/6aeDAc7DjR8EnhVKLLpy5WyizMmj85pI7eHHmT0Wln3YwsET4Ez4fO8cR9XkM9+ATYWE4eMwPB+/1+LwRyI+E80p+pp03PHlfp80bCV57oi7490mkwsfpplPnsN6ZtqufWJYY+9Mv8xPu1E+1kz7dlrPNDPuHkv8XCbDk5OlE4uzLK6lYgKHjQQCfPFpeUJ86BkN9wd/CTOpbg3N2TYuDx2Wd4fSUn/Tyyr6ekIK+WpjBomXBz8prTl9eLMLAK1M+DYSfDvb+Frb8ALzkGm5LQHMbwamR0j+60mCGGf8wvTjzson+sEq9+CnhP12DkJhoFM51PS+UhHNJEE9tQCshUQephiBkk/WQLHnuRSiOQiEfPo6ePl3x9zjGzrmhMEiE04XRIKyHjp/5dzVmJgfzkounD+ympSXPF8/9QddZKOgXikQC0tng5+I3nL68kIf+/ZMbgoGD4cKSAJzxCqOSI+ty1y09Kj/taqYpVymVNiBTGx0vljQsU+dR5npj+59pvUJ4dFs/+Sc1dXqacB6f1xDOH5t3hn2d76eUYqGkARgNPt5P1yCcNp2ffrvCyORl490FZV5pNtMjlPy/KfP/17T/N4rBax77t5vuZ9Ly8N90NsvH1yn5PzK2jiVPD+vmpZOnGzNBw7AAKejjIpkKu3D0zeJYSCTDUNF5GDl/GqFJRCTmFPQiIjGnoBcRiTkFvYhIzCnoRURiTkEvIhJzCnoRkZhT0IuIxFzVjV5pZr3AS+exi3bgcIXKWej0Xkym92MyvR8T4vBeXOzuHdMtqLqgP19mtnmmoTprjd6LyfR+TKb3Y0Lc3wt13YiIxJyCXkQk5uIY9PdGXUAV0Xsxmd6PyfR+TIj1exG7PnoREZksjkf0IiJSQkEvIhJzsQl6M9tgZs+b2W4zuyPqeqJkZivN7Akz22ZmW83sE1HXFDUzS5rZ78zs/0ZdS9TMbLGZPWxmO8xsu5lNc8uy2mFmfxr+nWwxs++ZWezu9hKLoDezJHAPcD3QCXzEzDqjrSpSeeA/unsncC3wb2v8/QD4BLA96iKqxFeAv3f31wBXUMPvi5nlgH8PrHP3biAJ3BxtVZUXi6AH1gO73f1Fdx8BHgRujLimyLj7AXd/JnzeT/CHnIu2quiY2QrgvcC3o64lamaWAa4D/hLA3UfcvS/aqiKXAprMLAU0A/sjrqfi4hL0OWBvyXQPNRxspcxsFXAV8A/RVhKpu4H/BBSjLqQKrAZ6ge+EXVnfNrOWqIuKirvvA74EvAwcAI67+6PRVlV5cQl6mYaZLQK+D/wHdz8RdT1RMLN/Chxy96ejrqVKpICrga+7+1XAIFCz57TMbAnBp//VQBZoMbNboq2q8uIS9PuAlSXTK8J5NcvM6ghC/m/c/QdR1xOhNwE3mNkegi69t5vZ/dGWFKkeoMfdxz7hPUwQ/LXqnwB/cPdedx8FfgC8MeKaKi4uQb8JWGNmq82snuBkyiMR1xQZMzOCPtjt7v7lqOuJkrt/xt1XuPsqgv8XP3P32B2xlcvdXwH2mtll4ax3ANsiLClqLwPXmllz+HfzDmJ4cjoVdQGV4O55M7sd+AnBWfP73H1rxGVF6U3AvwB+b2bPhvP+s7tvjG01O30AAABWSURBVLAmqR7/Dvib8KDoReBPIq4nMu7+D2b2MPAMwdVqvyOGwyFoCAQRkZiLS9eNiIjMQEEvIhJzCnoRkZhT0IuIxJyCXkQk5hT0IiIxp6AXEYm5/w8OKpFDu6bsfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation set is 0.07729346\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_val)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "loss = mse(y_val, predictions)\n",
    "print('Loss on validation set is %s' % loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points with score more than 0.7 150:\n",
      "Loss on validation set is 0.21956944\n"
     ]
    }
   ],
   "source": [
    "# More fine grained accuracy calculations\n",
    "huge_score = np.squeeze(np.argwhere(y_val > 0.7))\n",
    "print('Data points with score more than 0.7 %s:' % len(huge_score))\n",
    "val_data = x_val[huge_score,:]\n",
    "y_true = y_val[huge_score]\n",
    "predictions = model.predict(val_data)\n",
    "loss = mse(y_true, predictions)\n",
    "print('Loss on validation set is %s' % loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points with score less than 0.3 467:\n",
      "Loss on validation set is 0.08386848\n"
     ]
    }
   ],
   "source": [
    "# More fine grained accuracy calculations\n",
    "huge_score = np.squeeze(np.argwhere(y_val < 0.3))\n",
    "print('Data points with score less than 0.3 %s:' % len(huge_score))\n",
    "val_data = x_val[huge_score,:]\n",
    "y_true = y_val[huge_score]\n",
    "predictions = model.predict(val_data)\n",
    "loss = mse(y_true, predictions)\n",
    "print('Loss on validation set is %s' % loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points with score greater than 0.3 and less than 0.7 399:\n",
      "Loss on validation set is 0.015760617\n"
     ]
    }
   ],
   "source": [
    "# More fine grained accuracy calculations\n",
    "huge_score = np.squeeze(np.argwhere((y_val > 0.3) & (y_val < 0.7)))\n",
    "print('Data points with score greater than 0.3 and less than 0.7 %s:' % len(huge_score))\n",
    "val_data = x_val[huge_score,:]\n",
    "y_true = y_val[huge_score]\n",
    "predictions = model.predict(val_data)\n",
    "loss = mse(y_true, predictions)\n",
    "print('Loss on validation set is %s' % loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
