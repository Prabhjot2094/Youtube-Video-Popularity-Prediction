{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas) (2.7.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_features = pd.read_csv('./LIWC2015 Results (data-kushal).csv')\n",
    "liwc_features = liwc_features.fillna(0)\n",
    "liwc_features = liwc_features.drop(['Source (A)', 'Source (C)', 'Source (D)'], axis = 1)\n",
    "liwc_features = liwc_features.rename(columns={'Source (B)': 'video_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed_video/audio_xCgk9nvuCxk_txt failed processing\n",
      "./processed_video/audio_Q_ouhkdo-ko_txt failed processing\n",
      "\n",
      "Shape of labels:  (3389,)\n"
     ]
    }
   ],
   "source": [
    "# Read all the data\n",
    "labels = []\n",
    "labels_mapping = {}\n",
    "label_count = 0\n",
    "df = pd.read_csv('./raw_data.csv')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    path = os.path.join('./processed_video', 'audio_' + row['video_id'] + '_txt')\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                file_data = json.load(f)\n",
    "                labels.append((row['video_likeCount'] - row['video_dislikeCount'])/row['video_viewCount'])\n",
    "                labels_mapping[row['video_id']] = label_count\n",
    "                label_count = label_count + 1\n",
    "                \n",
    "            except ValueError:\n",
    "                print(path + ' failed processing')\n",
    "\n",
    "labels = np.array(labels)\n",
    "print()\n",
    "print('Shape of labels: ', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.021500000000000002, -0.0122]       1\n",
      "(-0.0122, -0.00398]                    7\n",
      "(-0.00398, 0.00421]                  225\n",
      "(0.00421, 0.0124]                   1094\n",
      "(0.0124, 0.0206]                    1021\n",
      "(0.0206, 0.0288]                     613\n",
      "(0.0288, 0.037]                      264\n",
      "(0.037, 0.0452]                      103\n",
      "(0.0452, 0.0533]                      31\n",
      "(0.0533, 0.0615]                      17\n",
      "(0.0615, 0.0697]                       5\n",
      "(0.0697, 0.0779]                       2\n",
      "(0.0779, 0.0861]                       1\n",
      "(0.0861, 0.0943]                       1\n",
      "(0.0943, 0.102]                        0\n",
      "(0.102, 0.111]                         1\n",
      "(0.111, 0.119]                         1\n",
      "(0.119, 0.127]                         0\n",
      "(0.127, 0.135]                         1\n",
      "(0.135, 0.143]                         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_series = pd.Series(labels)\n",
    "print(label_series.value_counts(bins=20).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for cnn lstm by concatenating frames, normalizing labels and defining constants\n",
    "labels = np.clip(labels, 0.00421, 0.037)\n",
    "min_label = np.min(labels)\n",
    "max_label = np.max(labels)\n",
    "scaled_labels = (labels - min_label)/(max_label - min_label)\n",
    "\n",
    "y = []\n",
    "for label in scaled_labels:\n",
    "    if label >= 0.0 and label < 0.2:\n",
    "        y.append(0)\n",
    "    elif label >= 0.2 and label < 0.4:\n",
    "        y.append(1)\n",
    "    elif label >= 0.4 and label < 0.6:\n",
    "        y.append(2)\n",
    "    elif label >= 0.6 and label < 0.8:\n",
    "        y.append(3)\n",
    "    elif label >= 0.8 and label <= 1.0:\n",
    "        y.append(4)\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.zeros((3389, 50))\n",
    "\n",
    "for video_id, index in labels_mapping.items():\n",
    "    video_features = liwc_features.loc[liwc_features.video_id == video_id, ['compare', 'i', 'Colon', 'home', 'focuspast', 'pronoun', 'ppron', 'anx', 'Dash',\n",
    " 'Sixltr', 'Analytic', 'auxverb', 'friend', 'OtherP', 'informal', 'number',\n",
    " 'assent', 'WC', 'we', 'WPS', 'function', 'verb', 'negemo', 'family', 'Apostro',\n",
    " 'ipron', 'feel', 'prep', 'body', 'relig', 'sexual', 'insight', 'cogproc',\n",
    " 'filler', 'they', 'conj', 'leisure', 'Dic', 'netspeak', 'negate', 'focuspresent',\n",
    " 'QMark', 'AllPunc', 'affiliation', 'work', 'space', 'article', 'Authentic',\n",
    " 'health', 'death']].to_numpy()\n",
    "    video_features = np.mean(video_features, axis = 0)\n",
    "    inputs[index, :] = video_features\n",
    "    del video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input features: (3389,50)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of input features: (%s,%s)' % inputs.shape)\n",
    "inputs[np.where(np.isnan(inputs))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training tensor: (2373, 50)\n",
      "Shape of training labels: (2373,)\n",
      "Shape of testing tensor: (1016, 50)\n",
      "Shape of testing labels: (1016,)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(inputs.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = inputs[indices]\n",
    "labels = y[indices]\n",
    "nb_validation_samples = int(0.3 * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "print('Shape of training tensor:', x_train.shape)\n",
    "print('Shape of training labels:', y_train.shape)\n",
    "print('Shape of testing tensor:', x_val.shape)\n",
    "print('Shape of testing labels:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.48      0.43       332\n",
      "           1       0.29      0.27      0.28       271\n",
      "           2       0.26      0.31      0.28       196\n",
      "           3       0.17      0.11      0.13       111\n",
      "           4       0.13      0.07      0.09       106\n",
      "\n",
      "    accuracy                           0.31      1016\n",
      "   macro avg       0.25      0.25      0.24      1016\n",
      "weighted avg       0.29      0.31      0.29      1016\n",
      "\n",
      "\n",
      "The final F1 micro score for the model based one arly fusion is:  0.3080708661417323\n",
      "\n",
      "Detailed Confusion Matrix\n",
      "\n",
      "[[160  85  55  17  15]\n",
      " [109  74  59  16  13]\n",
      " [ 58  48  60  17  13]\n",
      " [ 36  32  26  12   5]\n",
      " [ 41  18  33   7   7]]\n"
     ]
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth = 10).fit(x_train, y_train) \n",
    "y_pred = dtree_model.predict(x_val) \n",
    "y_true = y_val\n",
    "print(classification_report(y_true, y_pred, labels = [0,1,2,3,4], zero_division=0))\n",
    "print()\n",
    "print(\"The final F1 micro score for the model based one arly fusion is: \", f1_score(y_true, y_pred, average = 'micro', labels=[0,1,2,3,4]))\n",
    "print()\n",
    "print(\"Detailed Confusion Matrix\")\n",
    "print()\n",
    "print(confusion_matrix(y_true, y_pred, labels = [0, 1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=20, break_ties=False, cache_size=200,\n",
       "                                     class_weight=None, coef0=0.0,\n",
       "                                     decision_function_shape='ovr', degree=3,\n",
       "                                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                     probability=False, random_state=None,\n",
       "                                     shrinking=True, tol=0.001, verbose=False),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=10,\n",
       "                  max_samples=50, n_estimators=20, n_jobs=None, oob_score=False,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaggingClassifier(base_estimator=SVC(C = 20), n_estimators=20, max_features=10, max_samples=50)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.97      0.49       332\n",
      "           1       0.33      0.06      0.10       271\n",
      "           2       0.00      0.00      0.00       196\n",
      "           3       0.00      0.00      0.00       111\n",
      "           4       0.00      0.00      0.00       106\n",
      "\n",
      "    accuracy                           0.33      1016\n",
      "   macro avg       0.13      0.21      0.12      1016\n",
      "weighted avg       0.20      0.33      0.19      1016\n",
      "\n",
      "\n",
      "The final F1 micro score for the model based one arly fusion is:  0.3316929133858268\n",
      "\n",
      "Detailed Confusion Matrix\n",
      "\n",
      "[[321  11   0   0   0]\n",
      " [255  16   0   0   0]\n",
      " [187   9   0   0   0]\n",
      " [109   2   0   0   0]\n",
      " [ 96  10   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_true = y_val\n",
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(y_true, y_pred, labels = [0,1,2,3,4], zero_division=0))\n",
    "print()\n",
    "print(\"The final F1 micro score for the model based one arly fusion is: \", f1_score(y_true, y_pred, average = 'micro', labels=[0,1,2,3,4]))\n",
    "print()\n",
    "print(\"Detailed Confusion Matrix\")\n",
    "print()\n",
    "print(confusion_matrix(y_true, y_pred, labels = [0, 1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
