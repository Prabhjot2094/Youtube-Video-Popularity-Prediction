{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas) (2.7.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.18.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/kldsouza/Library/Python/3.7/lib/python/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (42.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from nltk) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.7.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install bs4\n",
    "!pip install nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all', quiet = True)\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "   \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "   \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "   \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "   \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "   \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "   \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "   \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "   \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "   \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "   \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "   \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "   \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "   \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "   \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "   \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "   \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "   \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed_video/audio_xCgk9nvuCxk_txt failed processing\n",
      "./processed_video/audio_Q_ouhkdo-ko_txt failed processing\n",
      "\n",
      "Shape of raw_inputs:  (3389,)\n",
      "Shape of labels:  (3389,)\n",
      "Max Words:  84\n",
      "Max Frames:  186\n",
      "Max Sequence Lenghth:  1500\n"
     ]
    }
   ],
   "source": [
    "# Read all the data\n",
    "labels = []\n",
    "raw_inputs = []\n",
    "df = pd.read_csv('./raw_data.csv')\n",
    "max_frames = 0\n",
    "max_words = 0\n",
    "max_sequence_length = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    path = os.path.join('./processed_video', 'audio_' + row['video_id'] + '_txt')\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                raw_inputs_video = []\n",
    "                sequence_length = 0\n",
    "                file_data = json.load(f)\n",
    "                num_frames = len(file_data)\n",
    "                \n",
    "                if num_frames > max_frames:\n",
    "                    max_frames = num_frames\n",
    "\n",
    "                for i in range(num_frames):\n",
    "                    line_data = json.loads(file_data[i])\n",
    "\n",
    "                    if 'DisplayText' in line_data.keys():\n",
    "                        sentence = line_data['DisplayText']\n",
    "                        cleaned_sentence = text_cleaner(sentence)\n",
    "                        num_words = len(cleaned_sentence.split())\n",
    "                        sequence_length = sequence_length + num_words\n",
    "\n",
    "                        if num_words > max_words:\n",
    "                            max_words = num_words\n",
    "                        raw_inputs_video.append(cleaned_sentence)\n",
    "\n",
    "                    del line_data\n",
    "                \n",
    "                raw_inputs.append(raw_inputs_video)\n",
    "                labels.append((row['video_likeCount'] - row['video_dislikeCount'])/row['video_viewCount'])\n",
    "                \n",
    "                if sequence_length > max_sequence_length:\n",
    "                    max_sequence_length = sequence_length\n",
    "\n",
    "                del raw_inputs_video, file_data, sequence_length\n",
    "            except ValueError:\n",
    "                print(path + ' failed processing')\n",
    "\n",
    "raw_inputs = np.array(raw_inputs)\n",
    "labels = np.array(labels)\n",
    "print()\n",
    "print('Shape of raw_inputs: ', raw_inputs.shape)\n",
    "print('Shape of labels: ', labels.shape)\n",
    "print('Max Words: ', max_words)\n",
    "print('Max Frames: ', max_frames)\n",
    "print('Max Sequence Lenghth: ', max_sequence_length)\n",
    "np.save('./text.npy', raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.021500000000000002, -0.0122]       1\n",
      "(-0.0122, -0.00398]                    7\n",
      "(-0.00398, 0.00421]                  225\n",
      "(0.00421, 0.0124]                   1094\n",
      "(0.0124, 0.0206]                    1021\n",
      "(0.0206, 0.0288]                     613\n",
      "(0.0288, 0.037]                      264\n",
      "(0.037, 0.0452]                      103\n",
      "(0.0452, 0.0533]                      31\n",
      "(0.0533, 0.0615]                      17\n",
      "(0.0615, 0.0697]                       5\n",
      "(0.0697, 0.0779]                       2\n",
      "(0.0779, 0.0861]                       1\n",
      "(0.0861, 0.0943]                       1\n",
      "(0.0943, 0.102]                        0\n",
      "(0.102, 0.111]                         1\n",
      "(0.111, 0.119]                         1\n",
      "(0.119, 0.127]                         0\n",
      "(0.127, 0.135]                         1\n",
      "(0.135, 0.143]                         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_series = pd.Series(labels)\n",
    "print(label_series.value_counts(bins=20).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for cnn lstm by concatenating frames, normalizing labels and defining constants\n",
    "text_inputs = [''.join(row) for row in raw_inputs]\n",
    "labels = np.clip(labels, 0.00421, 0.037)\n",
    "min_label = np.min(labels)\n",
    "max_label = np.max(labels)\n",
    "scaled_labels = (labels - min_label)/(max_label - min_label)\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "one_hot_labels = np.zeros((len(scaled_labels), 5))\n",
    "\n",
    "for index, label in enumerate(scaled_labels):\n",
    "    if label >= 0 and label <= 0.2:\n",
    "        one_hot_labels[index, 0] = 1\n",
    "    elif label > 0.2 and label <= 0.4:\n",
    "        one_hot_labels[index, 1] = 1\n",
    "    elif label > 0.4 and label <= 0.6:\n",
    "        one_hot_labels[index, 2] = 1\n",
    "    elif label > 0.6 and label <= 0.8:\n",
    "        one_hot_labels[index, 3] = 1\n",
    "    elif label > 0.8 and label <= 1:\n",
    "        one_hot_labels[index, 4] = 1\n",
    "\n",
    "one_hot_labels = np.array(one_hot_labels)\n",
    "\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = max_sequence_length\n",
    "VALIDATION_SPLIT = 0.3\n",
    "GLOVE_DIR = './glove.twitter.27B'\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121402 unique tokens.\n",
      "Shape of data tensor: (3389, 1500)\n",
      "Shape of label tensor: (3389, 5)\n",
      "Shape of training tensor: (2373, 1500)\n",
      "Shape of training labels: (2373, 5)\n",
      "Shape of testing tensor: (1016, 1500)\n",
      "Shape of testing labels: (1016, 5)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(text_inputs)\n",
    "sequences = tokenizer.texts_to_sequences(text_inputs)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', one_hot_labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = one_hot_labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "print('Shape of training tensor:', x_train.shape)\n",
    "print('Shape of training labels:', y_train.shape)\n",
    "print('Shape of testing tensor:', x_val.shape)\n",
    "print('Shape of testing labels:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.twitter.27B.200d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1500, 200)         24280600  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1496, 60)          60060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 299, 60)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 295, 60)           18060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 55, 60)            18060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 60)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 305       \n",
      "=================================================================\n",
      "Total params: 24,377,085\n",
      "Trainable params: 96,485\n",
      "Non-trainable params: 24,280,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2373 samples, validate on 1016 samples\n",
      "Epoch 1/15\n",
      "2373/2373 [==============================] - 14s 6ms/sample - loss: 1.5928 - categorical_accuracy: 0.2651 - val_loss: 1.5725 - val_categorical_accuracy: 0.2461\n",
      "Epoch 2/15\n",
      "2373/2373 [==============================] - 13s 6ms/sample - loss: 1.5343 - categorical_accuracy: 0.2642 - val_loss: 1.5261 - val_categorical_accuracy: 0.3297\n",
      "Epoch 3/15\n",
      "2373/2373 [==============================] - 15s 6ms/sample - loss: 1.5081 - categorical_accuracy: 0.3388 - val_loss: 1.5181 - val_categorical_accuracy: 0.3287\n",
      "Epoch 4/15\n",
      "2373/2373 [==============================] - 15s 6ms/sample - loss: 1.4976 - categorical_accuracy: 0.3430 - val_loss: 1.5150 - val_categorical_accuracy: 0.3386\n",
      "Epoch 5/15\n",
      "2373/2373 [==============================] - 12s 5ms/sample - loss: 1.4923 - categorical_accuracy: 0.3397 - val_loss: 1.5141 - val_categorical_accuracy: 0.3366\n",
      "Epoch 6/15\n",
      "2373/2373 [==============================] - 14s 6ms/sample - loss: 1.4848 - categorical_accuracy: 0.3451 - val_loss: 1.5159 - val_categorical_accuracy: 0.3317\n",
      "Epoch 7/15\n",
      "2373/2373 [==============================] - 13s 5ms/sample - loss: 1.4798 - categorical_accuracy: 0.3481 - val_loss: 1.5163 - val_categorical_accuracy: 0.3307\n",
      "Epoch 8/15\n",
      "2373/2373 [==============================] - 12s 5ms/sample - loss: 1.4756 - categorical_accuracy: 0.3493 - val_loss: 1.5206 - val_categorical_accuracy: 0.3356\n",
      "Epoch 9/15\n",
      "2373/2373 [==============================] - 12s 5ms/sample - loss: 1.4727 - categorical_accuracy: 0.3498 - val_loss: 1.5183 - val_categorical_accuracy: 0.3346\n",
      "Epoch 10/15\n",
      "2373/2373 [==============================] - 13s 5ms/sample - loss: 1.4702 - categorical_accuracy: 0.3510 - val_loss: 1.5205 - val_categorical_accuracy: 0.3337\n",
      "Epoch 11/15\n",
      "2373/2373 [==============================] - 13s 5ms/sample - loss: 1.4685 - categorical_accuracy: 0.3510 - val_loss: 1.5221 - val_categorical_accuracy: 0.3366\n",
      "Epoch 12/15\n",
      "2373/2373 [==============================] - 15s 6ms/sample - loss: 1.4679 - categorical_accuracy: 0.3515 - val_loss: 1.5211 - val_categorical_accuracy: 0.3337\n",
      "Epoch 13/15\n",
      "2373/2373 [==============================] - 13s 5ms/sample - loss: 1.4663 - categorical_accuracy: 0.3515 - val_loss: 1.5254 - val_categorical_accuracy: 0.3366\n",
      "Epoch 14/15\n",
      "2373/2373 [==============================] - 13s 6ms/sample - loss: 1.4663 - categorical_accuracy: 0.3515 - val_loss: 1.5229 - val_categorical_accuracy: 0.3346\n",
      "Epoch 15/15\n",
      "2373/2373 [==============================] - 12s 5ms/sample - loss: 1.4652 - categorical_accuracy: 0.3515 - val_loss: 1.5299 - val_categorical_accuracy: 0.3346\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(60, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-20, l2=1.e-20))(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(60, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-20, l2=1.e-20))(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(60, 5, activation='relu', kernel_regularizer=l1_l2(l1=1.e-20, l2=1.e-20))(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "preds = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# happy learning!\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.98      0.50       331\n",
      "           1       0.46      0.05      0.09       259\n",
      "           2       0.25      0.00      0.01       208\n",
      "           3       0.00      0.00      0.00       118\n",
      "           4       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33      1016\n",
      "   macro avg       0.21      0.21      0.12      1016\n",
      "weighted avg       0.28      0.33      0.19      1016\n",
      "\n",
      "\n",
      "The final F1 micro score for the model based one arly fusion is:  0.3346456692913386\n",
      "\n",
      "Detailed Confusion Matrix\n",
      "\n",
      "[[326   5   0   0   0]\n",
      " [243  13   3   0   0]\n",
      " [201   6   1   0   0]\n",
      " [116   2   0   0   0]\n",
      " [ 98   2   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_val), axis = 1)\n",
    "y_true = np.argmax(y_val, axis = 1)\n",
    "print(classification_report(y_true, y_pred, labels = [0,1,2,3,4], zero_division=0))\n",
    "print()\n",
    "print(\"The final F1 micro score for the model based one arly fusion is: \", f1_score(y_true, y_pred, average = 'micro', labels=[0,1,2,3,4]))\n",
    "print()\n",
    "print(\"Detailed Confusion Matrix\")\n",
    "print()\n",
    "print(confusion_matrix(y_true, y_pred, labels = [0, 1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
